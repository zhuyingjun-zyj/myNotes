#  <div align='center' ><font size='70'>短文本理解的难点和解决方案</font></div>

### 短文本理解的概念

所谓的理解，其实就是对文本进行理解或者说信息抽取，相信这个大家都好懂，常见的就是分类、实体识别和语义相似度之类的任务，而短文本则是在强调文本的性质，大都是长度较短的，这个长度我给个概念吧，长度绝大部分在15以下吧，不排除有极端的在样本里，但是应该很少见了，也有极端短的，例如3个字以下的，就这类型的样本，我把他叫做短文本吧。


+ 首先，显而易见，就是长度短。

+ 长度短，意味着句子的信息会比较少了，信息少其实并不利于做内容解析，这点无论对模型，还是对人都类似。

+ 信息少，有几个情况：

  + 极端少的，会导致信息模糊甚至无意义，例如“我”这种，表意不明，或者是“苹果”这种，有歧义。

  +  有些会隐藏一些知识，缺乏的话就理解不了，如“戴因斯雷布”（游戏角色）、“氧氟沙星”（一种西药）、“DC调光”（手机配置信息）等，没有一些背景知识，是理解不了的。

这些就是短文本背后所隐含的性质，为了方便大家理解，我尝试把句子拉长，但凡句子信息多一些，很多内容其实我们要做识别就会简单很多，因为句子中很可能隐含一些描述信息，例如“苹果”这个词，句子信息长一些，“苹果的续航怎么样”，一下子就能明白，这个值的是苹果品牌的设备，而不可能是水果的那个苹果，再举个例子，“哈哈哈哈哈”，就是一个很模糊的需求，不看综艺的很难想象这是一部综艺，但是一旦加长成“我想看哈哈哈哈哈”，这个时候我们差不多能猜到他可能是一部什么节目，可以看的，当然，也可以是什么风景之类的，但至少范围缩小了，这点其实和现在比较火的prompt类似，给出关键提示能让问题明朗很多。\

### 短文本问题的解决方案

说到解决方案，开始给答案之前，我先列举一下这个场景下大家容易问出的问题：

纯名词的预测比较不准。
大模型对短文本预测的效果相比小模型提升不大。
其实很多时候，就是因为信息问题，所以导致这些问题会比较凸显：

 - 纯名词都不认识，只能靠上下文猜，短文本又不见得有上下文。
 - 对大小模型而言，都缺一些预测需要的关键信息，所以就被卡着了，这些句子在现有的训练集下就是训不出来。
而这些问题，有时候大家会发现，好像都在增加样本之后，能一定程度优化，而且在一些时候，提升的幅度下降比较慢，其实就是因为，我们在增加样本的过程，给模型学到了很多新的知识，因为样本里藏有让模型学到的关键信息，例如句子里有“氧氟沙星”、“青霉素”、“氯雷他定”之类的信息，模型学到了，知道这些东西都是药品相关，那预测的时候就能预测的出来了，之前的样本里没有，现在增加了，预测能力自然就提升了，很明显，再者，模型大的信息容量大，而且调整起来兼容性高，所以学起新知识来比较快，差距就会逐渐明显了。

聊完了，大家也就明白，短文本的问题本质就是信息少，因此我们需要的就是给模型灌入更多的信息，而灌入信息的方法，我理解，来去就是两个：

 - **从模型层面增加信息**。通过更多更丰富的样本灌入协助训练，样本中蕴含信息，无论是further pretrain那种学习方式，还是直接做自身任务的进一步学习，增加样本的学习。（这里好像可以挖坑？）
 - **从特征层面加入**，加入一些附带信息的特征，例如词典附带的ner信息，例如大家可以看看这篇论文呢：Chinese NER Using Lattice LSTM，这里不展开了了。（这里好像也可以挖坑？）
这些就是从根本上解决问题的方案。前者想展开聊一点，也是大家可能比较常用、简单的方案了，尤其是增加样本这里，这块的方法我把他叫**实体增强**。

### 实体增强

所谓的实体增强，**就是用实体词典中的词汇，用来替换样本中的实体**，举个例子。样本里有一个，“我想看战狼2”，这里“战狼2”显然是电影词典里的一个词，我们可以换成别的，例如“我想看使徒行者”，通过这种方式，能让模型有效学到，“使徒行者”这是一个和“战狼2”类似的东西，这个其实就足够了，模型会自己做泛化和参考，当然了，为了避免模型在遇到“我想看张三”之类比较奇怪的预测，我们可以加一些“我想看阿巴阿巴”、“我想看烫烫烫”之类的对抗样本，避免模型错判。

